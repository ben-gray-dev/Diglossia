import { Observable, pipe, Subject, BehaviorSubject } from 'rxjs';
import { filter, map } from 'rxjs/operators';
import { InjectionToken, Injectable, ApplicationRef, Inject, Optional, NgModule, PLATFORM_ID } from '@angular/core';
import { isPlatformBrowser } from '@angular/common';

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
if (window['webkitSpeechRecognition']) {
    window['SpeechRecognition'] = window['webkitSpeechRecognition'];
}
if (window['webkitSpeechGrammarList']) {
    window['SpeechGrammarList'] = window['webkitSpeechGrammarList'];
}

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/** @type {?} */
const SpeechRecognitionGrammars = new InjectionToken('speech-recognition.grammars');
/** @type {?} */
const SpeechRecognitionLang = new InjectionToken('speech-recognition.lang');
/** @type {?} */
const SpeechRecognitionContinuous = new InjectionToken('speech-recognition.continuous');
/** @type {?} */
const SpeechRecognitionInterimResults = new InjectionToken('speech-recognition.interimResults');
/** @type {?} */
const SpeechRecognitionMaxAlternatives = new InjectionToken('speech-recognition.maxAlternatives');
/** @type {?} */
const SpeechRecognitionServiceUri = new InjectionToken('speech-recognition.serviceURI');
/** @type {?} */
const SpeechRecognitionAudiostartHandler = new InjectionToken('speech-recognition.onaudiostart');
/** @type {?} */
const SpeechRecognitionSoundstartHandler = new InjectionToken('speech-recognition.onsoundstart');
/** @type {?} */
const SpeechRecognitionSpeechstartHandler = new InjectionToken('speech-recognition.onspeechstart');
/** @type {?} */
const SpeechRecognitionSpeechendHandler = new InjectionToken('speech-recognition.onspeechend');
/** @type {?} */
const SpeechRecognitionSoundendHandler = new InjectionToken('speech-recognition.onsoundend');
/** @type {?} */
const SpeechRecognitionAudioendHandler = new InjectionToken('speech-recognition.onaudioend');
/** @type {?} */
const SpeechRecognitionResultHandler = new InjectionToken('speech-recognition.onresult');
/** @type {?} */
const SpeechRecognitionNomatchHandler = new InjectionToken('speech-recognition.onnomatch');
/** @type {?} */
const SpeechRecognitionErrorHandler = new InjectionToken('speech-recognition.onerror');
/** @type {?} */
const SpeechRecognitionStartHandler = new InjectionToken('speech-recognition.onstart');
/** @type {?} */
const SpeechRecognitionEndHandler = new InjectionToken('speech-recognition.onend');

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
class SpeechRecognitionCommon {
    /**
     * @param {?} _grammars
     * @param {?} _lang
     * @param {?} _continuous
     * @param {?} _interimResults
     * @param {?} _maxAlternatives
     * @param {?} _serviceURI
     */
    constructor(_grammars, _lang, _continuous, _interimResults, _maxAlternatives, _serviceURI) {
        this._grammars = _grammars;
        this._lang = _lang;
        this._continuous = _continuous;
        this._interimResults = _interimResults;
        this._maxAlternatives = _maxAlternatives;
        this._serviceURI = _serviceURI;
        this.internal = new SpeechRecognition();
    }
    /**
     * Property
     * @return {?}
     */
    // The grammars property of the SpeechRecognition interface returns and sets
    // a collection of SpeechGrammar objects
    // that represent the grammars that will be understood
    // by the current SpeechRecognition.
    //
    // SpeechRecognitionインターフェイスのgrammarsプロパティは、
    // 現在のSpeechRecognitionで認識される文法を表す
    // SpeechGrammarオブジェクトのコレクションを返して設定します。
    get grammars() {
        return this._grammars;
    }
    /**
     * @param {?} grammars
     * @return {?}
     */
    set grammars(grammars) {
        this._grammars = grammars;
        if (this._grammars !== undefined && this._grammars != null && this.internal) {
            this.internal.grammars = this._grammars;
        }
    }
    // The lang property of the SpeechRecognition interface returns
    // and sets the language of the current SpeechRecognition.
    // If not specified, this defaults to the HTML lang attribute value,
    // or the user agent's language setting if that isn't set either.
    //
    // SpeechRecognitionインターフェイスのlangプロパティは、
    // 現在のSpeechRecognitionの言語を返して設定します。
    // 指定されていない場合、これはデフォルトでHTMLのlang属性の値、
    // またはユーザエージェントの言語設定が設定されていない場合は
    // その値になります。
    /**
     * @return {?}
     */
    get lang() {
        return this._lang;
    }
    /**
     * @param {?} lang
     * @return {?}
     */
    set lang(lang) {
        this._lang = lang;
        if (this._lang !== undefined && this._lang != null && this.internal) {
            this.internal.lang = this._lang;
        }
    }
    // The continuous property of the SpeechRecognition interface controls
    // whether continuous results are returned for each recognition, or only a single result.
    //
    // SpeechRecognitionインターフェイスの連続プロパティは、
    // 認識結果ごとに連続した結果を返すか、単一の結果のみを返すかを制御します。
    /**
     * @return {?}
     */
    get continuous() {
        return this._continuous;
    }
    /**
     * @param {?} continuous
     * @return {?}
     */
    set continuous(continuous) {
        this._continuous = continuous;
        if (this._continuous !== undefined && this._continuous != null && this.internal) {
            this.internal.continuous = this._continuous;
        }
    }
    // The interimResults property of the SpeechRecognition interface controls
    // whether interim results should be returned (true)
    // or not (false.) Interim results are results that are not yet final
    // (e.g. the SpeechRecognitionResult.isFinal property is false.)
    //
    // SpeechRecognitionインターフェイスのinterimResultsプロパティは、
    // 中間結果を返すかどうか（true）、そうでないか（false）を制御します。
    // 中間結果は、最終段階ではない結果です（SpeechRecognitionResult.isFinalプロパティはfalseです）。
    /**
     * @return {?}
     */
    get interimResults() {
        return this._interimResults;
    }
    /**
     * @param {?} interimResults
     * @return {?}
     */
    set interimResults(interimResults) {
        this._interimResults = interimResults;
        if (this._interimResults !== undefined && this._interimResults != null && this.internal) {
            this.internal.interimResults = this._interimResults;
        }
    }
    // The maxAlternatives property of the SpeechRecognition interface sets
    // the maximum number of SpeechRecognitionAlternatives
    // provided per SpeechRecognitionResult.
    //
    // SpeechRecognitionインターフェイスのmaxAlternativesプロパティは、
    // SpeechRecognitionResultごとに提供される
    // SpeechRecognitionAlternativesの最大数を設定します。
    /**
     * @return {?}
     */
    get maxAlternatives() {
        return this._maxAlternatives;
    }
    /**
     * @param {?} maxAlternatives
     * @return {?}
     */
    set maxAlternatives(maxAlternatives) {
        this._maxAlternatives = maxAlternatives;
        if (this._maxAlternatives !== undefined && this._maxAlternatives != null && this.internal) {
            this.internal.maxAlternatives = this._maxAlternatives;
        }
    }
    // The serviceURI property of the SpeechRecognition interface specifies
    // the location of the speech recognition service
    // used by the current SpeechRecognition to handle
    // the actual recognition. The default is the user agent's
    // default speech service.
    //
    // SpeechRecognitionインターフェイスのserviceURIプロパティは、
    // 現在のSpeechRecognitionが実際の認識を処理するために使用する
    // 音声認識サービスの場所を指定します。
    // デフォルトはユーザエージェントのデフォルト音声サービスです。
    /**
     * @return {?}
     */
    get serviceURI() {
        return this._serviceURI;
    }
    /**
     * @param {?} serviceURI
     * @return {?}
     */
    set serviceURI(serviceURI) {
        this._serviceURI = serviceURI;
        if (this._serviceURI !== undefined && this._serviceURI != null && this.internal) {
            this.internal.serviceURI = this._serviceURI;
        }
    }
}

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
/** @type {?} */
const onType = (/**
 * @param {?} type
 * @return {?}
 */
(type) => {
    return filter((/**
     * @param {?} e
     * @return {?}
     */
    (e) => (e.type === type)));
});
/** @type {?} */
const resultList = pipe(onType('result'), map((/**
 * @param {?} e
 * @return {?}
 */
(e) => e.results)));
class RxSpeechRecognitionService extends SpeechRecognitionCommon {
    /**
     * @param {?} ref
     * @param {?} grammars
     * @param {?} lang
     * @param {?} continuous
     * @param {?} interimResults
     * @param {?} maxAlternatives
     * @param {?} serviceURI
     */
    constructor(ref, grammars, lang, continuous, interimResults, maxAlternatives, serviceURI) {
        super(grammars, lang, continuous, interimResults, maxAlternatives, serviceURI);
        this.ref = ref;
        this.proxy$ = new Subject();
        this._started$ = new BehaviorSubject(false);
        this.initInternal();
    }
    /**
     * @return {?}
     */
    get $() {
        return (/** @type {?} */ (this.proxy$));
    }
    /**
     * @return {?}
     */
    get started$() {
        return (/** @type {?} */ (this._started$));
    }
    /**
     * @private
     * @return {?}
     */
    initInternal() {
        // set handlers
        /** @type {?} */
        const handler = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.proxy$.next(e);
            this.ref.tick();
        });
        /** @type {?} */
        const errHandler = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.proxy$.error(e);
            this.ref.tick();
        });
        this.internal.onaudiostart = handler;
        this.internal.onsoundstart = handler;
        this.internal.onspeechstart = handler;
        this.internal.onspeechend = handler;
        this.internal.onsoundend = handler;
        this.internal.onaudioend = handler;
        this.internal.onresult = handler;
        this.internal.onnomatch = handler;
        this.internal.onerror = errHandler;
        this.internal.onstart = handler;
        this.internal.onend = handler;
        // see setter methods
        this.grammars = this._grammars;
        this.lang = this._lang;
        this.continuous = this._continuous;
        this.interimResults = this._interimResults;
        this.maxAlternatives = this._maxAlternatives;
        this.serviceURI = this._serviceURI;
        this.proxy$.subscribe((/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            switch (e.type) {
                case 'start':
                    this._started$.next(true);
                    break;
                case 'end':
                    this._started$.next(false);
                    break;
            }
        }));
    }
    // The listen() method aims to recognize the grammar associated with the current SpeechRecognition,
    // Observable is returned for handling voice recognition service listening to incoming voice.
    // When you subscrive the return value, listening begins and listening ends when an end event occurs.
    // Interrupt listening by unsubscribing in the middle.
    //
    // listen() メソッドは、現在のSpeechRecognitionに
    // 関連付けられた文法を認識することを目的として、
    // 着信音声を聴取する音声認識サービスを扱うためのObservableが返されます。
    // 返り値をsubscriveすると聴取が開始され、endのイベントが発生すると聴取を終了します。
    // 途中でunsbscriveすることで聴取を中断します。
    /**
     * @return {?}
     */
    listen() {
        /** @type {?} */
        const listener = new Observable((/**
         * @param {?} ovserver
         * @return {?}
         */
        (ovserver) => {
            // create subscriotion
            /** @type {?} */
            const subscriotion = this.proxy$.subscribe({
                next: (/**
                 * @param {?} e
                 * @return {?}
                 */
                (e) => {
                    ovserver.next(e);
                    if (e.type && e.type === 'end') {
                        this.internal.stop();
                        ovserver.complete();
                        subscriotion.unsubscribe();
                    }
                }),
                error: (/**
                 * @param {?} e
                 * @return {?}
                 */
                (e) => ovserver.error(e)),
            });
            // Speech Recognition start
            this.internal.start();
            return (/**
             * @return {?}
             */
            () => {
                this.internal.abort();
                subscriotion.unsubscribe();
            });
        }));
        return listener;
    }
}
RxSpeechRecognitionService.decorators = [
    { type: Injectable }
];
/** @nocollapse */
RxSpeechRecognitionService.ctorParameters = () => [
    { type: ApplicationRef },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionGrammars,] }] },
    { type: String, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionLang,] }] },
    { type: Boolean, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionContinuous,] }] },
    { type: Boolean, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionInterimResults,] }] },
    { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionMaxAlternatives,] }] },
    { type: String, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionServiceUri,] }] }
];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
// @dynamic
/**
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition
 * @see https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API
 */
class SpeechRecognitionService extends SpeechRecognitionCommon {
    /**
     * @param {?} ref
     * @param {?} grammars
     * @param {?} lang
     * @param {?} continuous
     * @param {?} interimResults
     * @param {?} maxAlternatives
     * @param {?} serviceURI
     * @param {?} audiostartHandler
     * @param {?} soundstartHandler
     * @param {?} speechstartHandler
     * @param {?} speechendHandler
     * @param {?} soundendHandler
     * @param {?} audioendHandler
     * @param {?} resultHandler
     * @param {?} nomatchHandler
     * @param {?} errorHandler
     * @param {?} startHandler
     * @param {?} endHandler
     */
    constructor(ref, grammars, lang, continuous, interimResults, maxAlternatives, serviceURI, audiostartHandler, soundstartHandler, speechstartHandler, speechendHandler, soundendHandler, audioendHandler, resultHandler, nomatchHandler, errorHandler, startHandler, endHandler) {
        super(grammars, lang, continuous, interimResults, maxAlternatives, serviceURI);
        this.ref = ref;
        this.audiostartHandler = audiostartHandler;
        this.soundstartHandler = soundstartHandler;
        this.speechstartHandler = speechstartHandler;
        this.speechendHandler = speechendHandler;
        this.soundendHandler = soundendHandler;
        this.audioendHandler = audioendHandler;
        this.resultHandler = resultHandler;
        this.nomatchHandler = nomatchHandler;
        this.errorHandler = errorHandler;
        this.startHandler = startHandler;
        this.endHandler = endHandler;
        this.initHandlers();
        this.initInternal();
    }
    /**
     * @private
     * @return {?}
     */
    initHandlers() {
        /** @type {?} */
        const _ = (/**
         * @return {?}
         */
        () => { });
        if (!this.audiostartHandler) {
            this.audiostartHandler = _;
        }
        if (!this.soundstartHandler) {
            this.soundstartHandler = _;
        }
        if (!this.speechstartHandler) {
            this.speechstartHandler = _;
        }
        if (!this.speechendHandler) {
            this.speechendHandler = _;
        }
        if (!this.soundendHandler) {
            this.soundendHandler = _;
        }
        if (!this.audioendHandler) {
            this.audioendHandler = _;
        }
        if (!this.resultHandler) {
            this.resultHandler = _;
        }
        if (!this.nomatchHandler) {
            this.nomatchHandler = _;
        }
        if (!this.errorHandler) {
            this.errorHandler = _;
        }
        if (!this.startHandler) {
            this.startHandler = _;
        }
        if (!this.endHandler) {
            this.endHandler = _;
        }
    }
    /**
     * @private
     * @return {?}
     */
    initInternal() {
        // see setter methods
        this.grammars = this._grammars;
        this.lang = this._lang;
        this.continuous = this._continuous;
        this.interimResults = this._interimResults;
        this.maxAlternatives = this._maxAlternatives;
        this.serviceURI = this._serviceURI;
        this.internal.onaudiostart = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.audiostartHandler(e);
            this.ref.tick();
        });
        this.internal.onsoundstart = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.soundstartHandler(e);
            this.ref.tick();
        });
        this.internal.onspeechstart = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.speechstartHandler(e);
            this.ref.tick();
        });
        this.internal.onspeechend = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.speechendHandler(e);
            this.ref.tick();
        });
        this.internal.onsoundend = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.soundendHandler(e);
            this.ref.tick();
        });
        this.internal.onaudioend = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.audioendHandler(e);
            this.ref.tick();
        });
        this.internal.onresult = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.resultHandler(e);
            this.ref.tick();
        });
        this.internal.onnomatch = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.nomatchHandler(e);
            this.ref.tick();
        });
        this.internal.onerror = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.errorHandler(e);
            this.ref.tick();
        });
        this.internal.onstart = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.startHandler(e);
            this.ref.tick();
        });
        this.internal.onend = (/**
         * @param {?} e
         * @return {?}
         */
        (e) => {
            this.endHandler(e);
            this.ref.tick();
        });
    }
    // The onaudiostart property of the SpeechRecognition interface
    // represents an event handler that will run
    // when the user agent has started to capture audio
    // (when the audiostart event fires.)
    //
    // SpeechRecognitionインターフェイスのonaudiostartプロパティは、
    // ユーザーエージェントがオーディオのキャプチャを開始したとき
    // （audiostartイベントが発生したとき）に実行されるイベントハンドラを
    // 表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onaudiostart(handler) {
        this.audiostartHandler = handler;
    }
    // The onsoundstart property of the SpeechRecognition interface represents
    // an event handler that will run when any sound
    // — recognisable speech or not
    // — has been detected (when the soundstart event fires.)
    //
    // SpeechRecognitionインターフェイスのonsoundstartプロパティは、
    // サウンド認識可能な音声が検出されたときに実行されるイベントハンドラを表します
    // （サウンドスタートイベントが発生したとき）。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onsoundstart(handler) {
        this.soundstartHandler = handler;
    }
    // The onspeechstart property of the SpeechRecognition interface represents
    // an event handler that will run when sound recognised
    // by the speech recognition service as speech has been detected
    // (when the speechstart event fires.)
    //
    // SpeechRecognitionインターフェイスのonspeechstartプロパティは、
    // スピーチが検出されたとき（スピーチ開始イベントが発生したとき）に
    // 音声認識サービスによって認識されたサウンドが実行されるイベントハンドラを表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onspeechstart(handler) {
        this.speechstartHandler = handler;
    }
    // The onspeechend property of the SpeechRecognition interface represents
    // an event handler that will run when speech recognised
    // by the speech recognition service has stopped being detected
    // (when the speechend event fires.)
    //
    // SpeechRecognitionインターフェイスのonspeechendプロパティは、
    // 音声認識サービスによって認識された音声が検出されなくなったとき
    // （Speechendイベントが発生したとき）に実行されるイベントハンドラを表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onspeechend(handler) {
        this.speechendHandler = handler;
    }
    // The onsoundend property of the SpeechRecognition interface represents
    // an event handler that will run when any sound
    // — recognisable speech or not — has stopped being detected
    // (when the soundend event fires.)
    //
    // SpeechRecognitionインターフェイスのonsoundendプロパティは、
    // サウンド認識可能な音声が検出されなくなったときに実行されるイベントハンドラを表します
    // （サウンドエンドイベントが発生したとき）。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onsoundend(handler) {
        this.soundendHandler = handler;
    }
    // The onaudioend property of the SpeechRecognition interface represents
    // an event handler that will run
    // when the user agent has finished capturing audio
    // (when the audioend event fires.)
    //
    // SpeechRecognitionインターフェイスのonaudioendプロパティは、
    // ユーザーエージェントがオーディオのキャプチャを終了したとき
    // （オーディオエンドイベントが発生したとき）に実行されるイベントハンドラを表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onaudioend(handler) {
        this.audioendHandler = handler;
    }
    // The onresult property of the SpeechRecognition interface represents
    // an event handler that will run
    // when the speech recognition service returns a result
    // — a word or phrase has been positively recognized
    // and this has been communicated back to the app
    // (when the result event fires.)
    //
    // SpeechRecognitionインターフェイスのonresultプロパティは、
    // 音声認識サービスが結果を返すときに実行されるイベントハンドラを表します。
    // 単語やフレーズが確実に認識され、結果イベントが発生したときにアプリに返されます。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onresult(handler) {
        this.resultHandler = handler;
    }
    // The onnomatch property of the SpeechRecognition interface represents
    // an event handler that will run
    // when the speech recognition service returns
    // a final result with no significant recognition
    // (when the nomatch event fires.)
    //
    // This may involve some degree of recognition
    //  which doesn't meet or exceed the confidence threshold.
    //
    //
    // SpeechRecognitionインターフェイスのonnomatchプロパティは、
    // 音声認識サービスが重要な認識なしに（nomatchイベントが発生したとき）
    // 最終結果を返すときに実行されるイベントハンドラを表します。
    //
    // これには、ある程度の認識が必要であり、これは信頼限界を満たさないか、
    // 超えている。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onnomatch(handler) {
        this.nomatchHandler = handler;
    }
    // The onerror property of the SpeechRecognition interface represents
    // an event handler that will run
    // when a speech recognition error occurs
    // (when the error event fires.)
    //
    // SpeechRecognitionインターフェイスのonerrorプロパティは、
    // 音声認識エラーが発生したとき（エラーイベントが発生したとき）に
    // 実行されるイベントハンドラを表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onerror(handler) {
        this.errorHandler = handler;
    }
    // The onstart property of the SpeechRecognition interface represents
    // an event handler that will run when the speech
    // recognition service has begun listening
    // to incoming audio with intent to recognize grammars
    // associated with the current SpeechRecognition
    // (when the start event fires.)
    //
    //
    // SpeechRecognitionインターフェイスのonstartプロパティは、
    // 音声認識サービスが現在のSpeechRecognitionに関連付けられている文法を
    // 認識することを目的として着信オーディオを聴き始めたときに実行される
    // イベントハンドラを表します（開始イベントが発生したとき）。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onstart(handler) {
        this.startHandler = handler;
    }
    // The onend property of the SpeechRecognition interface represents
    // an event handler that will run when the speech recognition
    // service has disconnected (when the end event fires.)
    //
    // SpeechRecognitionインターフェイスのonendプロパティは、
    // 音声認識サービスが切断されたとき（終了イベントが発生したとき）に
    // 実行されるイベントハンドラを表します。
    /**
     * @param {?} handler
     * @return {?}
     */
    set onend(handler) {
        this.endHandler = handler;
    }
    // The start() method of the Web Speech API starts the speech recognition service
    // listening to incoming audio with intent to recognize grammars
    // associated with the current SpeechRecognition.
    //
    // Web Speech APIのstart（）メソッドは、現在のSpeechRecognitionに
    // 関連付けられた文法を認識することを目的として、
    // 着信音声を聴取する音声認識サービスを開始します。
    /**
     * @return {?}
     */
    start() {
        this.internal.start();
        this.ref.tick();
    }
    // The stop() method of the Web Speech API stops the speech recognition service
    // from listening to incoming audio, and attempts to return a SpeechRecognitionResult
    // using the audio captured so far.
    //
    // Web Speech APIのstop（）メソッドは、音声認識サービスが着信音声を聴取するのを停止し、
    // これまでに取得した音声を使用してSpeechRecognitionResultを返そうとします。
    /**
     * @return {?}
     */
    stop() {
        this.internal.stop();
        this.ref.tick();
    }
    // The abort() method of the Web Speech API stops the speech recognition service
    // from listening to incoming audio, and doesn't attempt to return
    // a SpeechRecognitionResult.
    //
    // Web Speech APIのabort（）メソッドは、音声認識サービスが着信オーディオを聴くのをやめ、
    // SpeechRecognitionResultを返そうとしません。
    /**
     * @return {?}
     */
    abort() {
        this.internal.abort();
        this.ref.tick();
    }
}
SpeechRecognitionService.decorators = [
    { type: Injectable }
];
/** @nocollapse */
SpeechRecognitionService.ctorParameters = () => [
    { type: ApplicationRef },
    { type: undefined, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionGrammars,] }] },
    { type: String, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionLang,] }] },
    { type: Boolean, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionContinuous,] }] },
    { type: Boolean, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionInterimResults,] }] },
    { type: Number, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionMaxAlternatives,] }] },
    { type: String, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionServiceUri,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionAudiostartHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionSoundstartHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionSpeechstartHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionSpeechendHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionSoundendHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionAudioendHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionResultHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionNomatchHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionErrorHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionStartHandler,] }] },
    { type: Function, decorators: [{ type: Optional }, { type: Inject, args: [SpeechRecognitionEndHandler,] }] }
];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
// tslint:disable-next-line:class-name
/** @type {?} */
const SPEECH_RECOGNITION_DEFAULT = [
    {
        provide: SpeechRecognitionContinuous,
        useValue: false,
    },
    {
        provide: SpeechRecognitionInterimResults,
        useValue: false,
    },
    {
        provide: SpeechRecognitionMaxAlternatives,
        useValue: 1,
    },
];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */
class SpeechRecognitionModule {
    /**
     * @param {?} platformId
     */
    constructor(platformId) {
        if (isPlatformBrowser(platformId) === false) {
            throw new Error('SpeechRecognitionModule: it run on PlatformBrowser.');
        }
    }
    /**
     * @param {?} config
     * @return {?}
     */
    static forRoot(config) {
        return {
            ngModule: SpeechRecognitionModule,
            providers: [
                // tslint:disable:max-line-length
                ...(config.grammars !== undefined && config.grammars != null ? [{ useValue: config.grammars, provide: SpeechRecognitionGrammars }] : []),
                ...(config.lang !== undefined && config.lang != null ? [{ useValue: config.lang, provide: SpeechRecognitionLang }] : []),
                ...(config.continuous !== undefined && config.continuous != null ? [{ useValue: config.continuous, provide: SpeechRecognitionContinuous }] : []),
                ...(config.interimResults !== undefined && config.interimResults != null ? [{ useValue: config.interimResults, provide: SpeechRecognitionInterimResults }] : []),
                ...(config.maxAlternatives !== undefined && config.maxAlternatives != null ? [{ useValue: config.maxAlternatives, provide: SpeechRecognitionMaxAlternatives }] : []),
                ...(config.serviceURI !== undefined && config.serviceURI != null ? [{ useValue: config.serviceURI, provide: SpeechRecognitionServiceUri }] : []),
                ...(config.onaudiostart instanceof Function ? [{ useValue: config.onaudiostart, provide: SpeechRecognitionAudiostartHandler }] : []),
                ...(config.onsoundstart instanceof Function ? [{ useValue: config.onsoundstart, provide: SpeechRecognitionSoundstartHandler }] : []),
                ...(config.onspeechstart instanceof Function ? [{ useValue: config.onspeechstart, provide: SpeechRecognitionSpeechstartHandler }] : []),
                ...(config.onspeechend instanceof Function ? [{ useValue: config.onspeechend, provide: SpeechRecognitionSpeechendHandler }] : []),
                ...(config.onsoundend instanceof Function ? [{ useValue: config.onsoundend, provide: SpeechRecognitionSoundendHandler }] : []),
                ...(config.onaudioend instanceof Function ? [{ useValue: config.onaudioend, provide: SpeechRecognitionAudioendHandler }] : []),
                ...(config.onresult instanceof Function ? [{ useValue: config.onresult, provide: SpeechRecognitionResultHandler }] : []),
                ...(config.onnomatch instanceof Function ? [{ useValue: config.onnomatch, provide: SpeechRecognitionNomatchHandler }] : []),
                ...(config.onerror instanceof Function ? [{ useValue: config.onerror, provide: SpeechRecognitionErrorHandler }] : []),
                ...(config.onstart instanceof Function ? [{ useValue: config.onstart, provide: SpeechRecognitionStartHandler }] : []),
                ...(config.onend instanceof Function ? [{ useValue: config.onend, provide: SpeechRecognitionEndHandler }] : []),
                { useClass: SpeechRecognitionService, provide: SpeechRecognitionService },
                { useClass: RxSpeechRecognitionService, provide: RxSpeechRecognitionService }
            ],
        };
    }
    /**
     * @param {?} config
     * @return {?}
     */
    static withConfig(config) {
        return {
            ngModule: SpeechRecognitionModule,
            providers: [
                // tslint:disable:max-line-length
                ...(config.grammars !== undefined && config.grammars != null ? [{ useValue: config.grammars, provide: SpeechRecognitionGrammars }] : []),
                ...(config.lang !== undefined && config.lang != null ? [{ useValue: config.lang, provide: SpeechRecognitionLang }] : []),
                ...(config.continuous !== undefined && config.continuous != null ? [{ useValue: config.continuous, provide: SpeechRecognitionContinuous }] : []),
                ...(config.interimResults !== undefined && config.interimResults != null ? [{ useValue: config.interimResults, provide: SpeechRecognitionInterimResults }] : []),
                ...(config.maxAlternatives !== undefined && config.maxAlternatives != null ? [{ useValue: config.maxAlternatives, provide: SpeechRecognitionMaxAlternatives }] : []),
                ...(config.serviceURI !== undefined && config.serviceURI != null ? [{ useValue: config.serviceURI, provide: SpeechRecognitionServiceUri }] : []),
                ...(config.onaudiostart instanceof Function ? [{ useValue: config.onaudiostart, provide: SpeechRecognitionAudiostartHandler }] : []),
                ...(config.onsoundstart instanceof Function ? [{ useValue: config.onsoundstart, provide: SpeechRecognitionSoundstartHandler }] : []),
                ...(config.onspeechstart instanceof Function ? [{ useValue: config.onspeechstart, provide: SpeechRecognitionSpeechstartHandler }] : []),
                ...(config.onspeechend instanceof Function ? [{ useValue: config.onspeechend, provide: SpeechRecognitionSpeechendHandler }] : []),
                ...(config.onsoundend instanceof Function ? [{ useValue: config.onsoundend, provide: SpeechRecognitionSoundendHandler }] : []),
                ...(config.onaudioend instanceof Function ? [{ useValue: config.onaudioend, provide: SpeechRecognitionAudioendHandler }] : []),
                ...(config.onresult instanceof Function ? [{ useValue: config.onresult, provide: SpeechRecognitionResultHandler }] : []),
                ...(config.onnomatch instanceof Function ? [{ useValue: config.onnomatch, provide: SpeechRecognitionNomatchHandler }] : []),
                ...(config.onerror instanceof Function ? [{ useValue: config.onerror, provide: SpeechRecognitionErrorHandler }] : []),
                ...(config.onstart instanceof Function ? [{ useValue: config.onstart, provide: SpeechRecognitionStartHandler }] : []),
                ...(config.onend instanceof Function ? [{ useValue: config.onend, provide: SpeechRecognitionEndHandler }] : []),
            ]
        };
    }
}
SpeechRecognitionModule.decorators = [
    { type: NgModule, args: [{
                providers: [
                    SPEECH_RECOGNITION_DEFAULT,
                ],
            },] }
];
/** @nocollapse */
SpeechRecognitionModule.ctorParameters = () => [
    { type: String, decorators: [{ type: Inject, args: [PLATFORM_ID,] }] }
];

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

/**
 * @fileoverview added by tsickle
 * @suppress {checkTypes,extraRequire,missingOverride,missingReturn,unusedPrivateMembers,uselessCode} checked by tsc
 */

export { SpeechRecognitionGrammars, SpeechRecognitionLang, SpeechRecognitionContinuous, SpeechRecognitionInterimResults, SpeechRecognitionMaxAlternatives, SpeechRecognitionServiceUri, SpeechRecognitionAudiostartHandler, SpeechRecognitionSoundstartHandler, SpeechRecognitionSpeechstartHandler, SpeechRecognitionSpeechendHandler, SpeechRecognitionSoundendHandler, SpeechRecognitionAudioendHandler, SpeechRecognitionResultHandler, SpeechRecognitionNomatchHandler, SpeechRecognitionErrorHandler, SpeechRecognitionStartHandler, SpeechRecognitionEndHandler, resultList, RxSpeechRecognitionService, SpeechRecognitionService, SPEECH_RECOGNITION_DEFAULT, SpeechRecognitionModule, SpeechRecognitionCommon as ɵa };

//# sourceMappingURL=kamiazya-ngx-speech-recognition.js.map